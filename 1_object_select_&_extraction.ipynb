{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# object selection form catalog\n",
    "\n",
    "currently it's just a simple selection S/N of Ha Hb fluxes > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from   astropy.table import Table, vstack, join, setdiff\n",
    "import numpy         as np\n",
    "from   astropy.coordinates import SkyCoord, match_coordinates_sky\n",
    "import astropy.units as u\n",
    "import warnings\n",
    "from   astropy.io.fits.card import VerifyWarning\n",
    "warnings.simplefilter('ignore', VerifyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoodsN sample prearation, agn selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial catalog\n",
    "gn   = Table.read('hlsp_clear_hst_wfc3_gdn_multi_v4.1_clear.fits')\n",
    "gn_m = Table.read('hlsp_clear_hst_wfc3-acs_gdn-3dhst_multi_v4.6_zout.fits')\n",
    "gn_cat = join(gn,gn_m,keys_left='ID',keys_right='id',join_type='left',metadata_conflicts='silent')\n",
    "#agn catalog crossmatch\n",
    "filename = \"goodsn_agn.txt\"\n",
    "with open(filename, \"r\") as file:\n",
    "    source_ids = file.readlines()\n",
    "source_ids = [line.strip() for line in source_ids]\n",
    "coord_agn = SkyCoord(source_ids,unit=(u.hourangle, u.deg))\n",
    "coord_obj = SkyCoord(gn_cat['ra'],gn_cat['dec'],unit=(u.deg,u.deg))\n",
    "idx,d2d,d3d = match_coordinates_sky(coord_agn,coord_obj)\n",
    "gn_cat['tag'] = ['agn' if index in idx[d2d.deg < 5/3600] else 'gxy' for index in range(len(gn_cat))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoodsS sample prearation, agn selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: '[10-7W]' did not parse as cds unit: Syntax error If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n"
     ]
    }
   ],
   "source": [
    "gs   = Table.read('hlsp_clear_hst_wfc3_gds_multi_v4.1_clear.fits')\n",
    "gs_m = Table.read('hlsp_clear_hst_wfc3-acs_gds-3dhst_multi_v4.6_zout.fits')\n",
    "gs_cat = join(gs,gs_m,keys_left='ID',keys_right='id',join_type='left',metadata_conflicts='silent')\n",
    "\n",
    "gs_agn = Table.read('goodss_agn.txt', \n",
    "        format='ascii',  \n",
    "        names=[\n",
    "            \"3DHST\", \"VLA\", \"CDF-S\", \"z\", \"RAdeg\", \"DEdeg\", \"f_z\", \"mtype-s\", \"mtype-c\",\n",
    "            \"xtype-l\", \"xtype-x\", \"rtype-r\", \"rtype-f\", \"otype-sp\", \"otype-se\", \"var\",\n",
    "            \"logL-i\", \"f_logL-i\", \"logL-s\", \"logL-x\", \"Mbh\", \"M*\", \"rTag\", \"xTag\", \"mTag\",\n",
    "            \"oTag\", \"logNH\", \"logLx\", \"logLint\", \"gamma\", \"er_gamma\", \"CType\", \"L3GHz\",\n",
    "            \"L6GHz\", \"q_L3GHz\", \"q_L6GHz\", \"q24Obs\", \"e_q24Obs\", \"q24crt\", \"alpha\",\n",
    "            \"er_alpha\", \"tau\", \"logL5100\", \"logL3um\", \"logL6um\", \"logL8um\", \"logL12um\",\n",
    "            \"logL20um\"])\n",
    "gs_cat['tag'] = ['agn' if id in gs_agn['3DHST'] else '/' for id in gs['ID']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stacking 2 catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_lis = vstack([gn_cat,gs_cat],metadata_conflicts='silent')\n",
    "cat_lis.write('full_object_catalog.fits',overwrite=True)\n",
    "\n",
    "cat_hasline = cat_lis[np.logical_and(cat_lis['Ha_FLUX'] >0, cat_lis['Hb_FLUX']>0)]\n",
    "sn_ha = cat_hasline['Ha_FLUX']/cat_hasline['Ha_FLUX_ERR']\n",
    "cat_hasline['sn_ha'] = sn_ha\n",
    "sn_hb = cat_hasline['Hb_FLUX']/cat_hasline['Hb_FLUX_ERR']\n",
    "cat_hasline['sn_hb'] = sn_hb\n",
    "selection = np.logical_and(sn_ha>5,sn_hb>5)\n",
    "obj_lis = cat_hasline[selection]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manual selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_selection = np.array((\n",
    "    ['ERSPRIME',43823],\n",
    "    ['ERSPRIME',45258],\n",
    "    ['ERSPRIME',45646],\n",
    "    ['GN1',37031],\n",
    "    ['GN1',37623],\n",
    "    ['GN2', 14895],\n",
    "    ['GN2', 16173],\n",
    "    ['GN2', 14895],\n",
    "    ['GN2', 16752],\n",
    "    ['GN2', 17579],\n",
    "    ['GN2', 17829],\n",
    "    ['GN2', 21552],\n",
    "    ['GN3', 28121],\n",
    "    ['GN3', 32166],\n",
    "    ['GN3', 32660],\n",
    "    ['GN3', 34570],\n",
    "    ['GN3', 34708],\n",
    "    ['GN3', 34838],\n",
    "    ['GN3', 35042],\n",
    "    ['GN3', 35568],\n",
    "    ['GN3', 35822],\n",
    "    ['GN3', 19075],\n",
    "    ['GN4', 24377],\n",
    "    ['GN4', 26015],\n",
    "    ['GN4', 27282],\n",
    "    ['GN5', 31789],\n",
    "    ['GN7', 13777],\n",
    "    ['GN7', 14716],\n",
    "    ['GN7', 15127],\n",
    "    ['GN7', 15204],\n",
    "    ['GN7', 15300],\n",
    "    ['GN7', 17352],\n",
    "    ['GN7', 23580],\n",
    "    ['GS1', 47214],\n",
    "    ['GS1', 47399],\n",
    "    ['GS1', 48850],\n",
    "    ['GS1', 49063],\n",
    "    ['GS2', 45633],\n",
    "    ['GS2', 45795],\n",
    "    ['GS3', 34363],\n",
    "    ['GS3', 37903],\n",
    "    ['GS3', 40611],\n",
    "    ['GS3', 41370],\n",
    "    ['GS4', 20698],\n",
    "    ['GS4', 29686],\n",
    "    ['GS4', 29717],\n",
    "    ['GS4', 29846],\n",
    "    ['GS5', 38513],\n",
    "    ['GS5', 42758],\n",
    "))\n",
    "\n",
    "ismatched = np.isin(obj_lis['ID'],manual_selection[:,1]) & np.isin(obj_lis['subfield'],manual_selection[:,0])\n",
    "obj_lis['manual_select'] = np.where(ismatched,'selected','keep') \n",
    "obj_lis.write('obj_lis_selected.fits',overwrite=True)\n",
    "\n",
    "print('total num of objs in the fields',len(cat_lis))\n",
    "print('num of objs after s/n selection:',len(obj_lis))\n",
    "print('num of obj after agn selection',len(obj_lis[obj_lis['tag']!='agn']))\n",
    "print('num of obj after agn selection',len(obj_lis[np.logical_and(obj_lis['tag']!='agn',obj_lis['manual_select']!='selected')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download spectrum from server.\n",
    "\n",
    "It is recommended that to run the script downloadSpectra in prompt because of potential stability issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract line maps from data products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 158/158 [00:37<00:00,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of obj processed: 158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'number' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 114>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber of failed obj\u001b[39m\u001b[38;5;124m'\u001b[39m,number)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 115\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal number of obj processed:\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mlen\u001b[39m(results))\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber of failed obj\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[43mnumber\u001b[49m)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'number' referenced before assignment"
     ]
    }
   ],
   "source": [
    "from    astropy.table       import Table\n",
    "import  numpy               as     np\n",
    "from    astropy.io          import fits\n",
    "\n",
    "from    tqdm                import tqdm\n",
    "import  os\n",
    "import  gc                                         \n",
    "\n",
    "#this gives the file name + prefix of an obj from the cat file\n",
    "def file_name(obj,prefix,filetype='fits'):\n",
    "    field = obj['subfield'].lower()\n",
    "    id    = str(obj['ID']).zfill(5)\n",
    "    return f\"hlsp_clear_hst_wfc3_{field}-{id}_g102-g141_v4_{prefix}.{filetype}\"\n",
    "\n",
    "\n",
    "def extract_HaHb(hdu):\n",
    "    \"\"\"\n",
    "\n",
    "    pass objs from obj_lis to extract ha hb lines\n",
    "\n",
    "    return: HDUlist with the following entry:\n",
    "\n",
    "    0 primary extension, same as original file\n",
    "\n",
    "    1 line-fit results\n",
    "\n",
    "    2 segmentation map\n",
    "\n",
    "    3 clear filter maps\n",
    "\n",
    "    4,5 Ha line map & line weight\n",
    "\n",
    "    6,7 Hb line map & line weight\n",
    "\n",
    "    \"\"\"\n",
    "    #set up a crop of 50x50 pix in the center\n",
    "    center_size = 50; shape = hdu[5].shape[0]\n",
    "    #start index: si and end index: ei\n",
    "    si = (shape - center_size) // 2; \n",
    "    ei = si + center_size\n",
    "\n",
    "    new_file = fits.HDUList()\n",
    "    #save primary extension\n",
    "    new_file.append(hdu[0])\n",
    "    #save line-fit info\n",
    "    new_file.append(hdu[1])\n",
    "    \"\"\"\n",
    "    select segmentation map [4]\n",
    "    also save 1 DSCI image for comparison [5]\n",
    "    \"\"\"\n",
    "    for i in [4,5]: \n",
    "        hdu[i].data = hdu[i].data[si:ei,si:ei]\n",
    "        new_file.append(hdu[i])\n",
    "\n",
    "    #loop to select ha hb line maps\n",
    "    for image in hdu:\n",
    "        if image.header.get('EXTTYPE') in ['Ha','Hb'] and (image.name == 'LINE' or image.name == 'LINEWHT'):\n",
    "            image.data = image.data[si:ei,si:ei]\n",
    "            image.name = f\"{image.name}_{image.header['EXTTYPE']}\"\n",
    "            new_file.append(image)\n",
    "    return new_file\n",
    "\n",
    "\n",
    "def data_process(obj):\n",
    "    try:\n",
    "        path_data_product   = f\"data_products/{file_name(obj,'full')}\"\n",
    "        path_data_extracted = f\"data_extracted/{file_name(obj,'extracted')}\"\n",
    "\n",
    "        need_update_from_data_products = True\n",
    "        need_save_file = True\n",
    "\n",
    "        with fits.open(path_data_product) as hdu:\n",
    "            extracted = extract_HaHb(hdu)\n",
    "            ha_med = fits.ImageHDU(data = extracted[4].data - np.median(extracted[4].data),\n",
    "                                 header = extracted[4].header,name=f'{extracted[4].name}_bg')\n",
    "            hb_med = fits.ImageHDU(data = extracted[6].data - np.median(extracted[6].data),\n",
    "                                 header = extracted[6].header,name=f'{extracted[6].name}_bg')\n",
    "            extracted.append(ha_med)\n",
    "            extracted.append(hb_med)\n",
    "\n",
    "        #this part still needs psf matching---------\n",
    "        \n",
    "        #save file\n",
    "            extracted.writeto(path_data_extracted,overwrite=True)\n",
    "        return f\"{obj['subfield']}-{obj['ID']} saved\"\n",
    "\n",
    "    except Exception as e:\n",
    "            return f\"! {obj['subfield']}-{obj['ID']} failed, error:{e}\"\n",
    "\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "def main():\n",
    "    os.makedirs('data_extracted',exist_ok=True)\n",
    "    obj_lis = Table.read('obj_lis_selected.fits')\n",
    "    results = []\n",
    "    max_threads= 7\n",
    "    if max_threads > 1:\n",
    "        with ThreadPoolExecutor(max_threads) as executor:\n",
    "            futures = {executor.submit(data_process,obj):obj for obj in obj_lis}\n",
    "            for future in tqdm(as_completed(futures), total=len(obj_lis), desc=\"Processing\"):\n",
    "                results.append(future.result())\n",
    "    else:\n",
    "        for obj in tqdm(obj_lis):\n",
    "            results.append(data_process(obj))\n",
    "    number=0\n",
    "    for result in results:\n",
    "        if 'error' in result:\n",
    "            number +=1\n",
    "            print(result)\n",
    "    print('total number of obj processed:',len(results))\n",
    "    print('number of failed obj',number)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
